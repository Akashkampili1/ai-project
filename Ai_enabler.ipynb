{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/QgVzo7rRC0CO6y1wUSqK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "789fd5d1391d4b718342ff665dd1ab69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3a12545a4764b6d91cebff4fbe7a400",
              "IPY_MODEL_3ad64aa0ad9342079907ce38bc207274",
              "IPY_MODEL_03f7968ae7ac41e0be1d26624387d2e1"
            ],
            "layout": "IPY_MODEL_10ce3edd73f7400eb945a549d76154c5"
          }
        },
        "e3a12545a4764b6d91cebff4fbe7a400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01a2590e903046e281f56f7c8be11860",
            "placeholder": "​",
            "style": "IPY_MODEL_8279ccd8576f452199f67d50d2a41ea2",
            "value": "100%"
          }
        },
        "3ad64aa0ad9342079907ce38bc207274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e7fba202d134203a748c8511c54cea2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03b8aa86687f4bf8bf45a7dd80d8d5c5",
            "value": 1
          }
        },
        "03f7968ae7ac41e0be1d26624387d2e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd21bf3a37974f1aac5557aa46b7b69b",
            "placeholder": "​",
            "style": "IPY_MODEL_9b8d371b4b114f03a3bd4acc8c1d57a7",
            "value": " 1/1 [00:00&lt;00:00, 13.02it/s]"
          }
        },
        "10ce3edd73f7400eb945a549d76154c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01a2590e903046e281f56f7c8be11860": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8279ccd8576f452199f67d50d2a41ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e7fba202d134203a748c8511c54cea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b8aa86687f4bf8bf45a7dd80d8d5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd21bf3a37974f1aac5557aa46b7b69b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b8d371b4b114f03a3bd4acc8c1d57a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9b02411503140b7931e1d07e96e9166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d533191cd9e4a689d596af623a75103",
              "IPY_MODEL_7b491d4c6dd24dbca99a682ec2cb9526",
              "IPY_MODEL_8ff0ff8db837492f83ee151c71b92daf"
            ],
            "layout": "IPY_MODEL_6103d47539ac4100aef05f00040b1cba"
          }
        },
        "6d533191cd9e4a689d596af623a75103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8bac5ab862a4db6aa0e4261988edfac",
            "placeholder": "​",
            "style": "IPY_MODEL_b5fcee2f583045339356ecdf3f91823d",
            "value": "Map: 100%"
          }
        },
        "7b491d4c6dd24dbca99a682ec2cb9526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e1571a0836c40b39c3aa6fe8a619fff",
            "max": 9000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2dcbf5f28a5d4bf29ad158806ac8c403",
            "value": 9000
          }
        },
        "8ff0ff8db837492f83ee151c71b92daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a2392c9ddad4eabb1decc0516fe1450",
            "placeholder": "​",
            "style": "IPY_MODEL_851414b6e76a4a8dbd95eaaafab84b78",
            "value": " 9000/9000 [00:06&lt;00:00, 1450.64 examples/s]"
          }
        },
        "6103d47539ac4100aef05f00040b1cba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e8bac5ab862a4db6aa0e4261988edfac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5fcee2f583045339356ecdf3f91823d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e1571a0836c40b39c3aa6fe8a619fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dcbf5f28a5d4bf29ad158806ac8c403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a2392c9ddad4eabb1decc0516fe1450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "851414b6e76a4a8dbd95eaaafab84b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6fe64df3cff48bebaf3abb54f90deda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da8ae293cb9c4a38bf8f7751b14f5fa7",
              "IPY_MODEL_d58f609b3c7046a58cfeddfc47769324",
              "IPY_MODEL_5f8804bb5f9d4c41aa46ee8d48d7e1f6"
            ],
            "layout": "IPY_MODEL_c50743ae4a7042e08fd3421e403f4269"
          }
        },
        "da8ae293cb9c4a38bf8f7751b14f5fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c402b60786b496bbdf124debdfc8b25",
            "placeholder": "​",
            "style": "IPY_MODEL_5050a3d8d32743cfa9299810e7aa6388",
            "value": "Map: 100%"
          }
        },
        "d58f609b3c7046a58cfeddfc47769324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39b47008141747c48f0b2f1ff6f7fe83",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_037d29edb7ac4875894ec3f6add63c2b",
            "value": 1000
          }
        },
        "5f8804bb5f9d4c41aa46ee8d48d7e1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb44c50ae9d34a54a5edb50f315aac35",
            "placeholder": "​",
            "style": "IPY_MODEL_8337ae09871e4898b9c9ecf8ebc8b5a9",
            "value": " 1000/1000 [00:00&lt;00:00, 1651.85 examples/s]"
          }
        },
        "c50743ae4a7042e08fd3421e403f4269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "2c402b60786b496bbdf124debdfc8b25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5050a3d8d32743cfa9299810e7aa6388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39b47008141747c48f0b2f1ff6f7fe83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "037d29edb7ac4875894ec3f6add63c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb44c50ae9d34a54a5edb50f315aac35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8337ae09871e4898b9c9ecf8ebc8b5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akashkampili1/testet123/blob/main/Ai_enabler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCGfPNLUIkVF",
        "outputId": "fa5ff0b1-d3b8-486d-9a0c-7673bf6639fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version 2.12.0\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"  # reduce the amount of console output from TF\n",
        "import tensorflow as tf\n",
        "!pip install -q datasets \n",
        "!pip install -q transformers\n",
        "from transformers import *\n",
        " # install HF datasets library\n",
        "from datasets import load_dataset\n",
        "\n",
        "logging.set_verbosity_warning()\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "import logging\n",
        "\n",
        "print('TF version',tf.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU'))) # check GPU available"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_strategy(xla, fp16, no_cuda):\n",
        "    print(\" Tensorflow: setting up strategy\")\n",
        "    \n",
        "    # setup xla\n",
        "    if xla:\n",
        "        print(\" XLA Enabled\")\n",
        "        tf.config.optimizer.set_jit(True)\n",
        "    \n",
        "    # setup mixed precision training\n",
        "    if fp16:\n",
        "        # Set to float16 at first\n",
        "        print(\" Mixed Precision Training Enabled\")\n",
        "        policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
        "        tf.keras.mixed_precision.experimental.set_policy(policy)\n",
        "    \n",
        "    # setup distribution strategy\n",
        "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "    if no_cuda:\n",
        "        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
        "    else:\n",
        "        if len(gpus) == 0:\n",
        "            print(\" One Device Strategy [CPU] Enabled\")\n",
        "            strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
        "        elif len(gpus) == 1:\n",
        "            print(\" One Device Strategy [GPU] Enabled\")\n",
        "            strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
        "        elif len(gpus) > 1:\n",
        "            print(\" Mirrored Strategy Enabled\")\n",
        "            # If only want to use a specific subset of GPUs use CUDA_VISIBLE_DEVICES=0`\n",
        "            strategy = tf.distribute.MirroredStrategy()\n",
        "        else:\n",
        "            strategy = tf.distribute.get_strategy()\n",
        "\n",
        "    return strategy\n",
        "\n",
        "def n_replicas(strategy):\n",
        "    # return number of devices\n",
        "    return strategy.num_replicas_in_sync\n",
        "\n",
        "# note: \n",
        "# huggingface TF-T5 implementation has issues when mixed precision is enabled\n",
        "# we will disable FP16 for this but can be used for training any other model\n",
        "strategy = setup_strategy(xla=True, fp16=False, no_cuda=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3WTb2l1chgO",
        "outputId": "b884c9a9-2111-470d-aa42-618c9f307949"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tensorflow: setting up strategy\n",
            " XLA Enabled\n",
            " One Device Strategy [GPU] Enabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Open JSON file for writing\n",
        "with open('output.json', mode='w') as writer:\n",
        "\n",
        "    # Create a list to store sections data\n",
        "    sections = []\n",
        "\n",
        "    # Loop to generate 1000 sections\n",
        "    for i in range(1, 10001):\n",
        "        section_text = f'This is section {i}'\n",
        "        section_code = f'<section id=\"about{i}\">\\n  <h2>About Us</h2>\\n  <p>{section_text}</p>\\n</section>\\n'\n",
        "        data = {\"text\": section_text, \"code\": section_code}\n",
        "\n",
        "        # Append data to sections list\n",
        "        sections.append(data)\n",
        "\n",
        "    # Write sections data to JSON file\n",
        "    json.dump(sections, writer, indent=2)\n"
      ],
      "metadata": {
        "id": "8OtxSg2udBi8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_dataset(cache_dir):\n",
        "    # download data using a keras utility\n",
        "    _url = \"https://raw.githubusercontent.com/Akashkampili1/testet123/main/output.jsonl\" # download mbpp dataset\n",
        "    dataset_path = tf.keras.utils.get_file(\"output.jsonl\", origin=_url, cache_dir=cache_dir, cache_subdir=cache_dir)\n",
        "    return dataset_path \n",
        "\n",
        "def convert_examples_to_features(examples, tokenizer, args):\n",
        "    # encode text-code pairs\n",
        "    texts = examples['text']\n",
        "    codes = examples['code']\n",
        "    # tests = [\" \".join(test) for test in examples['test_list']] # convert list of test cases to single string\n",
        "    \n",
        "    # encode texts by prepending the task for input sequence\n",
        "    inputs = [args.prefix + text for text in texts]\n",
        "    model_inputs = tokenizer(inputs, max_length=args.max_input_length, padding=\"max_length\", truncation=True)\n",
        "    \n",
        "    # encode texts by prepending the task for input sequence and appending the test sequence\n",
        "    # inputs = [args.prefix + text + \" \" + test for text, test in zip(texts, tests)]\n",
        "    # model_inputs = tokenizer(inputs, max_length=args.max_input_length, padding=\"max_length\", truncation=True)\n",
        "    \n",
        "    # encode texts by prepending the task for input sequence\n",
        "    labels = tokenizer(codes, max_length=args.max_target_length, padding=\"max_length\", truncation=True).input_ids\n",
        "    \n",
        "    # we need to replace the index of the padding tokens by -100\n",
        "    # such that they are not taken into account by the CrossEntropyLoss\n",
        "    labels_with_ignore_index = []\n",
        "    for labels_example in labels:\n",
        "        labels_example = [label if label != 0 else -100 for label in labels_example]\n",
        "        labels_with_ignore_index.append(labels_example)\n",
        "    model_inputs[\"labels\"] = labels_with_ignore_index\n",
        "    \n",
        "    # return features\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "def get_train_tfdataset(train_dataset, num_train_examples, args):\n",
        "    # select feature columns\n",
        "    columns = ['input_ids', 'attention_mask', 'labels'] \n",
        "    # set to tensorflow format\n",
        "    train_dataset.set_format(type='tensorflow', columns=columns) \n",
        "    \n",
        "    # specify return types\n",
        "    return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, 'labels':tf.int32} \n",
        "    # specify return shapes\n",
        "    return_shapes = {'input_ids': tf.TensorShape([None]),'attention_mask': tf.TensorShape([None]), 'labels': tf.TensorShape([None])} \n",
        "    # initialize dataset \n",
        "    tf_dataset = tf.data.Dataset.from_generator(lambda : train_dataset, return_types, return_shapes) \n",
        "    \n",
        "    # turn off auto-sharding\n",
        "    options = tf.data.Options()\n",
        "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
        "    tf_dataset = tf_dataset.with_options(options)\n",
        "    \n",
        "    # repeat, shuffle, batch, prefetch\n",
        "    ds = (\n",
        "        tf_dataset.repeat()\n",
        "        .shuffle(num_train_examples, seed=args.seed)\n",
        "        .batch(args.train_batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "    \n",
        "    # distribute dataset to devices\n",
        "    return strategy.experimental_distribute_dataset(ds)\n",
        "\n",
        "def get_validation_tfdataset(eval_dataset, num_validation_examples, args):\n",
        "    # select feature columns\n",
        "    columns = ['input_ids', 'attention_mask', 'labels'] \n",
        "    # set to tensorflow format\n",
        "    eval_dataset.set_format(type='tensorflow', columns=columns) \n",
        "    \n",
        "    # specify return types\n",
        "    return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, 'labels':tf.int32} \n",
        "    # specify return shapes\n",
        "    return_shapes = {'input_ids': tf.TensorShape([None]),'attention_mask': tf.TensorShape([None]), 'labels': tf.TensorShape([None])} \n",
        "    # initialize dataset \n",
        "    tf_dataset = tf.data.Dataset.from_generator(lambda : eval_dataset, return_types, return_shapes) \n",
        "    \n",
        "    # turn off auto-sharding\n",
        "    options = tf.data.Options()\n",
        "    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
        "    tf_dataset = tf_dataset.with_options(options)\n",
        "    \n",
        "    # repeat, batch, prefetch\n",
        "    ds = (\n",
        "        tf_dataset.repeat()\n",
        "        .batch(args.validation_batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "    \n",
        "    # distribute dataset to devices\n",
        "    return strategy.experimental_distribute_dataset(ds)"
      ],
      "metadata": {
        "id": "PIjcu9QrcnPP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ki_sodcwcnSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "def fix_all_seeds(seed):\n",
        "    # set random seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    \n",
        "def init_logger(log_file=None, log_file_level=logging.NOTSET):\n",
        "    # initialize logger for tracking events and save in file\n",
        "    if isinstance(log_file, Path):\n",
        "        log_file = str(log_file)\n",
        "    log_format = logging.Formatter(\n",
        "        fmt='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "        datefmt='%m/%d/%Y %H:%M:%S'\n",
        "    )\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(logging.INFO)\n",
        "    console_handler = logging.StreamHandler()\n",
        "    console_handler.setFormatter(log_format)\n",
        "    logger.handlers = [console_handler]\n",
        "    if log_file and log_file != '':\n",
        "        file_handler = logging.FileHandler(log_file)\n",
        "        file_handler.setLevel(log_file_level)\n",
        "        # file_handler.setFormatter(log_format)\n",
        "        logger.addHandler(file_handler)\n",
        "    return logger\n",
        "\n",
        "class ProgressBar(object):\n",
        "    # custom progress bar\n",
        "    def __init__(self, n_total,width=30,desc = 'Training'):\n",
        "        self.width = width\n",
        "        self.n_total = n_total\n",
        "        self.start_time = time.time()\n",
        "        self.desc = desc\n",
        "\n",
        "    def __call__(self, step, info={}):\n",
        "        now = time.time()\n",
        "        current = step + 1\n",
        "        recv_per = current / self.n_total\n",
        "        bar = f'[{self.desc}] {current}/{self.n_total} ['\n",
        "        if recv_per >= 1:\n",
        "            recv_per = 1\n",
        "        prog_width = int(self.width * recv_per)\n",
        "        if prog_width > 0:\n",
        "            bar += '=' * (prog_width - 1)\n",
        "            if current< self.n_total:\n",
        "                bar += \">\"\n",
        "            else:\n",
        "                bar += '='\n",
        "        bar += '.' * (self.width - prog_width)\n",
        "        bar += ']'\n",
        "        show_bar = f\"\\r{bar}\"\n",
        "        time_per_unit = (now - self.start_time) / current\n",
        "        if current < self.n_total:\n",
        "            eta = time_per_unit * (self.n_total - current)\n",
        "            if eta > 3600:\n",
        "                eta_format = ('%d:%02d:%02d' %\n",
        "                              (eta // 3600, (eta % 3600) // 60, eta % 60))\n",
        "            elif eta > 60:\n",
        "                eta_format = '%d:%02d' % (eta // 60, eta % 60)\n",
        "            else:\n",
        "                eta_format = '%ds' % eta\n",
        "            time_info = f' - ETA: {eta_format}'\n",
        "        else:\n",
        "            if time_per_unit >= 1:\n",
        "                time_info = f' {time_per_unit:.1f}s/step'\n",
        "            elif time_per_unit >= 1e-3:\n",
        "                time_info = f' {time_per_unit * 1e3:.1f}ms/step'\n",
        "            else:\n",
        "                time_info = f' {time_per_unit * 1e6:.1f}us/step'\n",
        "\n",
        "        show_bar += time_info\n",
        "        if len(info) != 0:\n",
        "            show_info = f'{show_bar} ' + \\\n",
        "                        \"-\".join([f' {key}: {value:.4f} ' if key != \"learning_rate\" else f' {key}: {value:.8f} ' for key, value in info.items()])\n",
        "            print(show_info, end='')\n",
        "        else:\n",
        "            print(show_bar, end='')"
      ],
      "metadata": {
        "id": "7Rz6Hj4ecnVd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(\n",
        "        self, model, args, train_dataset, validation_dataset, \n",
        "        num_train_examples, num_validation_examples\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.args = args\n",
        "        \n",
        "        self.train_dataset = train_dataset\n",
        "        self.num_train_examples = num_train_examples\n",
        "        \n",
        "        self.validation_dataset = validation_dataset\n",
        "        self.num_validation_examples = num_validation_examples\n",
        "        \n",
        "        self.global_step = 0\n",
        "        self.eval_loss = tf.keras.metrics.Sum()\n",
        "        \n",
        "    def create_optimizer_and_scheduler(self, num_training_steps):\n",
        "        # creates an optimizer with a learning rate schedule using a warmup phase followed by a linear decay.\n",
        "        num_warmup_steps = math.ceil(num_training_steps * self.args.warmup_ratio)\n",
        "        self.optimizer, self.lr_scheduler = create_optimizer(\n",
        "            init_lr=self.args.learning_rate,\n",
        "            num_train_steps=num_training_steps,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            weight_decay_rate=self.args.weight_decay,\n",
        "            adam_epsilon=self.args.adam_epsilon\n",
        "        )\n",
        "    \n",
        "    def evaluation_step(self, features, labels, nb_instances_in_global_batch):\n",
        "        # forward pass\n",
        "        outputs = self.model(input_ids=features['input_ids'], attention_mask=features['attention_mask'], labels=labels, training=False)[:2]\n",
        "        loss, logits = outputs[:2]\n",
        "        # loss scaling\n",
        "        scaled_loss = loss / tf.cast(nb_instances_in_global_batch, dtype=loss.dtype)\n",
        "        # add current batch loss\n",
        "        self.eval_loss.update_state(scaled_loss)\n",
        "    \n",
        "    @tf.function\n",
        "    def distributed_evaluation_steps(self, batch):\n",
        "        features = {k: v for k, v in batch.items() if 'labels' not in k}\n",
        "        labels = batch['labels']\n",
        "        nb_instances = tf.reduce_sum(tf.cast(labels != -100, dtype=tf.int32))\n",
        "        # strategy.run() expects args to be a list or tuple\n",
        "        inputs = (features, labels, nb_instances)\n",
        "        # `run` replicates the provided computation and runs with the distributed input\n",
        "        strategy.run(self.evaluation_step, inputs)\n",
        "\n",
        "    def evaluate(self):\n",
        "        # calculate total validation steps\n",
        "        steps = math.ceil(self.num_validation_examples / self.args.validation_batch_size)\n",
        "        # reset eval loss after every epoch\n",
        "        self.eval_loss.reset_states()\n",
        "        logs = {}\n",
        "        pbar = ProgressBar(n_total=steps, desc='Evaluating')\n",
        "        # iterate over validation dataset\n",
        "        for step, batch in enumerate(self.validation_dataset): \n",
        "            # distributed evaluation step\n",
        "            self.distributed_evaluation_steps(batch) \n",
        "            logs[\"eval_loss\"] = self.eval_loss.result() / (step + 1)\n",
        "            pbar(step=step, info=logs)\n",
        "            if step == steps - 1:\n",
        "                break\n",
        "        print(\"\\n------------- validation result -----------------\")\n",
        "        \n",
        "    def apply_gradients(self, features, labels, nb_instances_in_global_batch):\n",
        "        # forward pass\n",
        "        outputs = self.model(input_ids=features['input_ids'], attention_mask=features['attention_mask'], labels=labels, training=True)[:2] \n",
        "        loss, logits = outputs[:2]\n",
        "        # loss scaling\n",
        "        scaled_loss = loss / tf.cast(nb_instances_in_global_batch, dtype=loss.dtype) \n",
        "        # calculate gradients\n",
        "        gradients = tf.gradients(scaled_loss, self.model.trainable_variables) \n",
        "        # convert gradients with nan value\n",
        "        gradients = [g if g is not None else tf.zeros_like(v) for g, v in zip(gradients, self.model.trainable_variables)] \n",
        "        # optimize the model\n",
        "        self.optimizer.apply_gradients(list(zip(gradients, self.model.trainable_variables))) \n",
        "        # add current batch loss\n",
        "        self.train_loss.update_state(scaled_loss) \n",
        "    \n",
        "    @tf.function\n",
        "    def distributed_training_steps(self, batch):\n",
        "        with strategy.scope():\n",
        "            features = {k: v for k, v in batch.items() if 'labels' not in k}\n",
        "            labels = batch['labels']\n",
        "            nb_instances = tf.reduce_sum(tf.cast(labels != -100, dtype=tf.int32))\n",
        "            # strategy.run() expects args to be a list or tuple\n",
        "            inputs = (features, labels, nb_instances)\n",
        "            # `run` replicates the provided computation and runs with the distributed input.\n",
        "            strategy.run(self.apply_gradients, inputs)\n",
        "    \n",
        "    \n",
        "    def train(self):\n",
        "        # calculate total training steps\n",
        "        num_updates_per_epoch = self.num_train_examples // args.train_batch_size \n",
        "        self.steps_per_epoch = num_updates_per_epoch\n",
        "        t_total = self.steps_per_epoch * self.args.epochs\n",
        "        \n",
        "        with strategy.scope():\n",
        "            # optimizer, and checkpoint must be created under `strategy.scope`\n",
        "            # create optimizer and scheduler\n",
        "            self.create_optimizer_and_scheduler(num_training_steps=t_total) \n",
        "            \n",
        "            # create checkpoint manager\n",
        "            folder = os.path.join(self.args.output_dir, self.args.checkpoint_dir)\n",
        "            ckpt = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model) \n",
        "            self.model.ckpt_manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n",
        "            iterations = self.optimizer.iterations\n",
        "            \n",
        "            logger.info(\"***** Running training *****\")\n",
        "            logger.info(f\"  Num examples = {self.num_train_examples}\")\n",
        "            logger.info(f\"  Num Epochs = {self.args.epochs}\")\n",
        "            logger.info(f\"  Total train batch size (w. parallel & distributed) = {self.args.train_batch_size * n_replicas(strategy)}\")\n",
        "            logger.info(f\"  Steps per epoch = {self.steps_per_epoch}\")\n",
        "            logger.info(f\"  Total optimization steps = {t_total}\")\n",
        "            \n",
        "            self.train_loss = tf.keras.metrics.Sum(name=\"training_loss\")\n",
        "            start_time = datetime.datetime.now()\n",
        "            for epoch_iter in range(self.args.epochs):\n",
        "                # training loop\n",
        "                logger.info(f\"Epoch {epoch_iter + 1}/{self.args.epochs}\")\n",
        "                \n",
        "                pbar = ProgressBar(n_total=self.steps_per_epoch, desc='Training')\n",
        "                # iterate over training dataset\n",
        "                for step, batch in enumerate(self.train_dataset):    \n",
        "                    # distributed training step\n",
        "                    self.distributed_training_steps(batch) \n",
        "                    \n",
        "                    self.global_step = iterations.numpy()\n",
        "                    training_loss = self.train_loss.result() / (step + 1)\n",
        "                    \n",
        "                    logs = {}\n",
        "                    logs[\"training_loss\"] = training_loss.numpy()\n",
        "                    logs[\"learning_rate\"] = self.lr_scheduler(self.global_step).numpy()\n",
        "                    pbar(step=step, info=logs)\n",
        "                    \n",
        "                    if self.global_step % self.steps_per_epoch == 0:\n",
        "                        print(\"\\n------------- train result -----------------\")\n",
        "                        # call to evaluation loop\n",
        "                        self.evaluate()\n",
        "                        # save checkpoint\n",
        "                        ckpt_save_path = self.model.ckpt_manager.save()\n",
        "                        logger.info(f\"Saving checkpoint at {ckpt_save_path}\")\n",
        "                        break\n",
        "                \n",
        "                # reset train loss after every epoch\n",
        "                self.train_loss.reset_states()\n",
        "            end_time = datetime.datetime.now()\n",
        "            logger.info(f\"Training took: {str(end_time - start_time)}\")"
      ],
      "metadata": {
        "id": "VxMSp9v8cnYh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(args):\n",
        "    logger.info(\" Starting training / evaluation\")\n",
        "    \n",
        "    logger.info(\" Downloading Data Files\")\n",
        "    dataset_path = [\"/content/output.json\"]\n",
        "\n",
        "    logger.info(\" Loading Data Files\")\n",
        "    dataset = load_dataset('json', data_files=dataset_path) \n",
        "    # train test split\n",
        "    dataset = dataset['train'].train_test_split(0.1, shuffle=False) \n",
        "        \n",
        "    logger.info(\" Initializing Tokenizer\")\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(args.tokenizer_name) \n",
        "    \n",
        "    logger.info(\" Preparing Features\")\n",
        "    dataset = dataset.map(convert_examples_to_features, batched=True, fn_kwargs={\"tokenizer\":tokenizer, \"args\":args})\n",
        "\n",
        "    logger.info(\" Intializing training and validation dataset \")\n",
        "    train_dataset = dataset['train']\n",
        "    num_train_examples = len(dataset['train'])\n",
        "    # create tf train dataset\n",
        "    tf_train_dataset = get_train_tfdataset(train_dataset, num_train_examples, args) \n",
        "    \n",
        "    validation_dataset = dataset['test']\n",
        "    num_validation_examples = len(dataset['test'])\n",
        "    # create tf validation dataset\n",
        "    tf_validation_dataset = get_validation_tfdataset(train_dataset, num_validation_examples, args) \n",
        "    \n",
        "    logger.info(f' Intializing model | {args.model_type.upper()} ')\n",
        "    with strategy.scope():\n",
        "        # model must be created under `strategy.scope`\n",
        "        model = TFT5ForConditionalGeneration.from_pretrained(args.model_name_or_path, from_pt=True)\n",
        "    \n",
        "    # custom training loop\n",
        "    trainer = Trainer(model, args, tf_train_dataset, tf_validation_dataset, num_train_examples, num_validation_examples) \n",
        "    trainer.train()\n",
        "    \n",
        "    # save pretrained model and tokenizer\n",
        "    logger.info(f\" Saving model in {args.save_dir}\")\n",
        "    trainer.model.save_pretrained(args.save_dir)\n",
        "    tokenizer.save_pretrained(args.save_dir)"
      ],
      "metadata": {
        "id": "qmsdhg-_cnbE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dfvQ_jmK7tFQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867,
          "referenced_widgets": [
            "789fd5d1391d4b718342ff665dd1ab69",
            "e3a12545a4764b6d91cebff4fbe7a400",
            "3ad64aa0ad9342079907ce38bc207274",
            "03f7968ae7ac41e0be1d26624387d2e1",
            "10ce3edd73f7400eb945a549d76154c5",
            "01a2590e903046e281f56f7c8be11860",
            "8279ccd8576f452199f67d50d2a41ea2",
            "3e7fba202d134203a748c8511c54cea2",
            "03b8aa86687f4bf8bf45a7dd80d8d5c5",
            "dd21bf3a37974f1aac5557aa46b7b69b",
            "9b8d371b4b114f03a3bd4acc8c1d57a7",
            "d9b02411503140b7931e1d07e96e9166",
            "6d533191cd9e4a689d596af623a75103",
            "7b491d4c6dd24dbca99a682ec2cb9526",
            "8ff0ff8db837492f83ee151c71b92daf",
            "6103d47539ac4100aef05f00040b1cba",
            "e8bac5ab862a4db6aa0e4261988edfac",
            "b5fcee2f583045339356ecdf3f91823d",
            "7e1571a0836c40b39c3aa6fe8a619fff",
            "2dcbf5f28a5d4bf29ad158806ac8c403",
            "2a2392c9ddad4eabb1decc0516fe1450",
            "851414b6e76a4a8dbd95eaaafab84b78",
            "d6fe64df3cff48bebaf3abb54f90deda",
            "da8ae293cb9c4a38bf8f7751b14f5fa7",
            "d58f609b3c7046a58cfeddfc47769324",
            "5f8804bb5f9d4c41aa46ee8d48d7e1f6",
            "c50743ae4a7042e08fd3421e403f4269",
            "2c402b60786b496bbdf124debdfc8b25",
            "5050a3d8d32743cfa9299810e7aa6388",
            "39b47008141747c48f0b2f1ff6f7fe83",
            "037d29edb7ac4875894ec3f6add63c2b",
            "eb44c50ae9d34a54a5edb50f315aac35",
            "8337ae09871e4898b9c9ecf8ebc8b5a9"
          ]
        },
        "outputId": "073a927d-2d9c-479b-92d9-3f092a791b7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/21/2023 15:55:46 - INFO - root -    Starting training / evaluation\n",
            "04/21/2023 15:55:46 - INFO - root -    Downloading Data Files\n",
            "04/21/2023 15:55:46 - INFO - root -    Loading Data Files\n",
            "04/21/2023 15:55:47 - WARNING - datasets.builder -   Found cached dataset json (/root/.cache/huggingface/datasets/json/default-50c019c16219dee5/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "789fd5d1391d4b718342ff665dd1ab69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/21/2023 15:55:47 - INFO - root -    Initializing Tokenizer\n",
            "04/21/2023 15:55:48 - INFO - root -    Preparing Features\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9b02411503140b7931e1d07e96e9166"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6fe64df3cff48bebaf3abb54f90deda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/21/2023 15:55:57 - INFO - root -    Intializing training and validation dataset \n",
            "04/21/2023 15:55:57 - INFO - root -    Intializing model | T5 \n",
            "04/21/2023 15:56:04 - INFO - root -   ***** Running training *****\n",
            "04/21/2023 15:56:04 - INFO - root -     Num examples = 9000\n",
            "04/21/2023 15:56:04 - INFO - root -     Num Epochs = 5\n",
            "04/21/2023 15:56:04 - INFO - root -     Total train batch size (w. parallel & distributed) = 8\n",
            "04/21/2023 15:56:04 - INFO - root -     Steps per epoch = 1125\n",
            "04/21/2023 15:56:04 - INFO - root -     Total optimization steps = 5625\n",
            "04/21/2023 15:56:04 - INFO - root -   Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] 1125/1125 [==============================] 421.2ms/step  training_loss: 0.0007 - learning_rate: 0.00030000 \n",
            "------------- train result -----------------\n",
            "[Evaluating] 125/125 [==============================] 200.3ms/step  eval_loss: 0.0001 \n",
            "------------- validation result -----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/21/2023 16:04:36 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-1\n",
            "04/21/2023 16:04:36 - INFO - root -   Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] 1125/1125 [==============================] 369.5ms/step  training_loss: 0.0000 - learning_rate: 0.00022500 \n",
            "------------- train result -----------------\n",
            "[Evaluating] 125/125 [==============================] 113.2ms/step  eval_loss: 0.0000 \n",
            "------------- validation result -----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/21/2023 16:11:57 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-2\n",
            "04/21/2023 16:11:57 - INFO - root -   Epoch 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] 1125/1125 [==============================] 369.1ms/step  training_loss: 0.0000 - learning_rate: 0.00015000 \n",
            "------------- train result -----------------\n",
            "[Evaluating] 125/125 [==============================] 114.2ms/step  eval_loss: 0.0000 \n",
            "------------- validation result -----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/21/2023 16:19:20 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-3\n",
            "04/21/2023 16:19:20 - INFO - root -   Epoch 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] 1125/1125 [==============================] 368.9ms/step  training_loss: 0.0000 - learning_rate: 0.00007500 \n",
            "------------- train result -----------------\n",
            "[Evaluating] 125/125 [==============================] 113.6ms/step  eval_loss: 0.0000 \n",
            "------------- validation result -----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/21/2023 16:26:41 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-4\n",
            "04/21/2023 16:26:41 - INFO - root -   Epoch 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training] 1125/1125 [==============================] 368.8ms/step  training_loss: 0.0000 - learning_rate: 0.00000000 \n",
            "------------- train result -----------------\n",
            "[Evaluating] 125/125 [==============================] 113.0ms/step  eval_loss: 0.0000 \n",
            "------------- validation result -----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "04/21/2023 16:34:02 - INFO - root -   Saving checkpoint at runs/checkpoint/ckpt-5\n",
            "04/21/2023 16:34:02 - INFO - root -   Training took: 0:37:57.818253\n",
            "04/21/2023 16:34:02 - INFO - root -    Saving model in runs//saved_model/\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import RobertaTokenizer\n",
        "from transformers import TFT5ForConditionalGeneration\n",
        "from transformers import create_optimizer\n",
        "from keras import backend\n",
        "\n",
        "\n",
        "\n",
        "class Args:\n",
        "    # define training arguments\n",
        "    \n",
        "    # MODEL\n",
        "    model_type = 't5'\n",
        "    tokenizer_name = 'Salesforce/codet5-base'\n",
        "    model_name_or_path = 'Salesforce/codet5-base'\n",
        "    \n",
        "    # DATA\n",
        "    train_batch_size = 8\n",
        "    validation_batch_size = 8\n",
        "    max_input_length = 48\n",
        "    max_target_length = 128\n",
        "    prefix = \"Generate Python: \"    \n",
        "\n",
        "    # OPTIMIZER\n",
        "    learning_rate = 3e-4\n",
        "    weight_decay = 1e-4\n",
        "    warmup_ratio = 0.2\n",
        "    adam_epsilon = 1e-8\n",
        "\n",
        "    # TRAINING\n",
        "    seed = 2022\n",
        "    epochs = 5\n",
        "\n",
        "    # DIRECTORIES\n",
        "    output_dir = \"runs/\"\n",
        "    logging_dir = f\"{output_dir}/logs/\"\n",
        "    checkpoint_dir = f\"checkpoint\"\n",
        "    save_dir = f\"{output_dir}/saved_model/\"\n",
        "    cache_dir = '../working/'\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "    Path(logging_dir).mkdir(parents=True, exist_ok=True)\n",
        "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "\n",
        "# initialize training arguments\n",
        "args = Args()\n",
        "# initialize logger\n",
        "logger = init_logger(log_file=os.path.join(args.logging_dir, f\"{args.model_type}-{time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime())}.log\"))\n",
        "# fix all seeds\n",
        "fix_all_seeds(args.seed)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # run training and evaluation\n",
        "    dataset = run(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_predict(args, text):\n",
        "    # load saved finetuned model\n",
        "    model = TFT5ForConditionalGeneration.from_pretrained(args.save_dir)\n",
        "    # load saved tokenizer\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(args.save_dir) \n",
        "    \n",
        "     # encode texts by prepending the task for input sequence and appending the test sequence\n",
        "    query = args.prefix + text \n",
        "    encoded_text = tokenizer(query, return_tensors='tf', padding='max_length', truncation=True, max_length=args.max_input_length)\n",
        "    \n",
        "    # inference\n",
        "    generated_code = model.generate(\n",
        "        encoded_text[\"input_ids\"], attention_mask=encoded_text[\"attention_mask\"], \n",
        "        max_length=args.max_target_length, top_p=0.95, top_k=50, repetition_penalty=2.0, num_return_sequences=1\n",
        "    )\n",
        "    \n",
        "    # decode generated tokens\n",
        "    decoded_code = tokenizer.decode(generated_code.numpy()[0], skip_special_tokens=True)\n",
        "    return decoded_code\n",
        "\n",
        "def predict_from_dataset(args):\n",
        "    # load using hf datasets\n",
        "    dataset = load_dataset('json', data_files='../working/output.jsonl') \n",
        "    # train test split\n",
        "    dataset = dataset['train'].train_test_split(0.1, shuffle=False) \n",
        "    test_dataset = dataset['test']\n",
        "    \n",
        "    # randomly select an index from the validation dataset\n",
        "    index = random.randint(0, len(test_dataset))\n",
        "    text = test_dataset[index]['text']\n",
        "    code = test_dataset[index]['code']\n",
        "    \n",
        "    # run-predict on text\n",
        "    decoded_code = run_predict(args, text)\n",
        "    \n",
        "    print(\"#\" * 25); print(\"QUERY: \", text); \n",
        "    print()\n",
        "    print('#' * 25); print(\"ORIGINAL: \"); print(\"\\n\", code);\n",
        "    print()\n",
        "    print('#' * 25); print(\"GENERATED: \"); print(\"\\n\", decoded_code);\n",
        "    \n",
        "def predict_from_text(args, text):\n",
        "    # run-predict on text\n",
        "    decoded_code = run_predict(args, text)\n",
        "    print(\"#\" * 25); print(\"QUERY: \", text); \n",
        "    print()\n",
        "    print('#' * 25); print(\"GENERATED: \"); print(\"\\n\", decoded_code);"
      ],
      "metadata": {
        "id": "zXQUuoRZcnej"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example 1\n",
        "predict_from_text(args, \"write code for a section  \"); print()\n",
        "# example 2\n",
        "predict_from_text(args, \"write code for a section 210\"); print()\n",
        "# example 3\n",
        "predict_from_text(args, \"write code for a section 506\"); print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4jb44Vfc1kM",
        "outputId": "cc4eac25-9783-43c7-ab9b-bf7329e949b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#########################\n",
            "QUERY:  write code for a section  \n",
            "\n",
            "#########################\n",
            "GENERATED: \n",
            "\n",
            " <section id=\"about855\">\n",
            "  <h2>About Us</ h 2 >\n",
            "  <=p>This is section .</ p>>\n",
            "</sections\n",
            "\n",
            "#########################\n",
            "QUERY:  write code for a section 210\n",
            "\n",
            "#########################\n",
            "GENERATED: \n",
            "\n",
            " <section id=\"about210\">\n",
            "  <h 2>About Us</ h3 >\n",
            "  <=p>This is section two 10.</ p>\"\n",
            "</section>\n",
            "\n",
            "\n",
            "#########################\n",
            "QUERY:  write code for a section 506\n",
            "\n",
            "#########################\n",
            "GENERATED: \n",
            "\n",
            " <section id=\"about506\">\n",
            "  <h2>About Us</ h 2 >\n",
            "  <=p>This is section 50 6.</ p>\"\n",
            "</section>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZhez-15hjyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN4S6fR5dW9o",
        "outputId": "aac7a15f-c618-4928-8fce-0e9abbcbc082"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    }
  ]
}